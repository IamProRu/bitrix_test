есть файл в несколько сотен тысяч строк
нужно его загрузить в БД
- как организуете хранение в БД?
- как будете загружать содержимое файла в БД?

### Вопрос 1
Слишком мало конкретики в постановке задачи, уточнений по моему вопросу не последовало, поэтому ответ будет очень абстрактный. 
Если данные в строках структурированы, то можно хранить в реляционной БД или, например, в ElasticSearch. Дальше очень сильно все зависит от того как эти данные будут использоваться в дальнейшем.
Если данные не структурированы, то можно хранить в нереляционной БД.

### Вопрос 2
Если говорить о хранении в реляционной БД, то, например, в MySQL максимальной скорости можно достичь, используя импорт из файла SQL-запросом `LOAD DATA INFILE`.
Если же считывание из файла недоступно из-за настроек безопасности, то нужно формировать запрос(ы) вида:

`INSERT INTO tbl_name (a,b,c) VALUES(1,2,3), (4,5,6), (7,8,9), ...`

При этом каждый запрос должен по размеру не превышать максимально разрешенный в настройках mysql размер `max_allowed_packet`. 
Такой подход позволит уменьшить количество перестроений индексов, если они есть. Если индексов в таблице много, и запросов формируется много, то можно перед вставкой данных удалить индексы, а затем снова их добавить. 
Кроме того можно изменить таблицы на MyISAM, если используется InnoDB, а после завершения вставки данных вернуть обратно InnoDB.
